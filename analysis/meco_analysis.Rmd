---
title: "Regressions: Analysis"
output: html_notebook
---

```{r}
shhh <- suppressPackageStartupMessages # It's a library, so shhh!

shhh(library( mgcv ))
shhh(library(dplyr))
shhh(library(ggplot2))
shhh(library(lme4))
shhh(library(tidymv))
shhh(library(gamlss))
shhh(library(gsubfn))
shhh(library(lmerTest))
shhh(library(tidyverse))
shhh(library(boot))
shhh(library(rsample))
shhh(library(plotrix))
shhh(library(ggrepel))
shhh(library(mgcv))
shhh(library(Hmisc))
shhh(library(jmuOutlier))
library("viridis")



#options(JULIA_HOME = "/Applications/Julia-1.8.app/Contents/Resources/julia/bin/")
#library(jglmm)
#jglmm_setup()


theme_set(theme_bw())
options(digits=4)
options(dplyr.summarise.inform = FALSE)
set.seed(444)
options(scipen=999)

```


# Read and Clean Data

```{r}

meco_pairwise_df = read.csv("../data/harmonized_results/meco_pairwise_stats_df.csv")
meco_sacc_df = read.csv("../data/harmonized_results/meco_saccades_df.csv")

```

```{r}

meco_agg_regressions = meco_sacc_df %>%
  mutate(next_ia_idx = as.numeric(next_ia_idx), prev_ia_idx = as.numeric(prev_ia_idx)) %>%
  drop_na() %>%
  filter(next_ia_idx < curr_ia_idx) %>%
  group_by(lang) %>%
    mutate(total_subj = length(unique(subj))) %>%
  ungroup() %>%
  group_by(text_id, sent_id, curr_ia_idx, next_ia_idx, lang) %>%
    summarise(n_regressions = n() ) %>%
  ungroup() %>%
  rename(
    trigger_idx = curr_ia_idx,
    target_idx = next_ia_idx
  ) %>%
  mutate(target_idx = as.integer(target_idx)) %>%
  # MECO uses different langauge codes than ISO
  mutate(lang = if_else(lang == "ge", "de", lang),
         lang = if_else(lang == "sp", "es", lang),
         lang = if_else(lang == "du", "nl", lang))

meco_df = meco_pairwise_df %>%
  mutate(text_id = text_id + 1, sent_id = sent_id + 1) %>%
  merge(meco_agg_regressions, by=c("text_id", "sent_id", "trigger_idx", "target_idx", "lang")) %>%
  mutate(corpus = "meco") %>%
  
  # For wrap-up effects analysis --> Filter out final words of sentences
  #mutate(dist = trigger_idx-target_idx) %>%
  #group_by(lang, text_id, sent_id) %>%
  #  mutate(max_idx = max(unique(trigger_idx))) %>%
  #ungroup() %>%
  #mutate(is_max = trigger_idx == max_idx) %>%
  #filter(is_max == F) %>%
  distinct()


meco_df %>%
  arrange(lang, text_id, sent_id, trigger_idx, target_idx)


```

Wrap-up Distance Effect
```{r}

wrap_up_df = meco_df %>%
  mutate(dist = trigger_idx-target_idx) %>%
  group_by(lang, text_id, sent_id) %>%
    mutate(max_idx = max(unique(trigger_idx))) %>%
  ungroup() %>%
  mutate(is_max = trigger_idx == max_idx)

wrap_up_df %>%
  filter(n_regressions > 0) %>%
  distinct() %>%
  group_by(is_max) %>%
    summarise(m = mean(dist)) %>%
  ungroup()

```


```{r}

combined_df = data.frame()
combined_df = rbind(combined_df, meco_df) %>%
  dplyr::select(-X)

combined_df = combined_df %>%
  mutate(n_regressions = if_else(is.na(n_regressions), 0, as.double(n_regressions)),
         #n_subjs = if_else(is.na(n_subjs), 0, as.double(n_subjs)),
         #prop_subj = if_else(is.na(prop_subj), 0, as.double(prop_subj)),
         target_len = scale(target_len),
         target_freq = scale(target_freq),
         target_surp = scale(target_surp),
         trigger_surp = scale(trigger_surp),
         trigger_len = scale(trigger_len),
         trigger_freq = scale(trigger_freq),
         
         pmi = scale(pmi),
         ppmi = scale(ppmi),
         npmi = scale(npmi),
         e_pmi = scale(e_pmi),
         e_ppmi = scale(e_ppmi),
         e_npmi = scale(-1 *  e_npmi),
         dist = scale(trigger_idx - target_idx)) %>%
  drop_na() %>%
  filter(is_multitok == "False")

combined_df


```



```{r}

model_cross_val_poisson = function(form, df, lang, tag, num_folds=10){
  
  folds <- cut(seq(1,nrow(df)),breaks=num_folds,labels=FALSE)
  
  estimates = data.frame()
  coeffs = data.frame()
  for(i in 1:num_folds){
    testIndexes = which(folds==i,arr.ind=TRUE)
    testData = df[testIndexes,]
    trainData = df[-testIndexes,]

    model = glm(as.formula(form), data = trainData, family = poisson())
    
    preds = testData %>% dplyr::select(n_regressions) %>% rename(y=n_regressions) %>% 
      mutate(pred = predict(model, newdata = testData)) %>% 
      mutate(fold = i)

    estimates = rbind(estimates, preds)
    coeffs = rbind(coeffs, tidy(model) %>% mutate(lang = lang, tag = tag, fold = i ) )
  }

  result = list(estimates, coeffs)
  return( result )
}

```


```{r, warning=FALSE}

model_cross_val_logistic = function(form, df, lang, tag, num_folds=10){
  
  folds <- cut(seq(1,nrow(df)),breaks=num_folds,labels=FALSE)
  
  estimates = data.frame()
  coeffs = data.frame()
  for(i in 1:num_folds){
    testIndexes = which(folds==i,arr.ind=TRUE)
    testData = df[testIndexes,]
    trainData = df[-testIndexes,]

    model = glm(as.formula(form), data = trainData, family = "quasibinomial")
    
    preds = testData %>% dplyr::select(prop_subj) %>% rename(y=prop_subj) %>% 
      mutate(pred = predict(model, newdata = testData)) %>% 
      mutate(fold = i)

    estimates = rbind(estimates, preds)
    coeffs = rbind(coeffs, tidy(model) %>% mutate(lang = lang, tag = tag, fold = i ) )
  }

  result = list(estimates, coeffs)
  return( result )
}

```

```{r, include = FALSE}

regression_forms = c(
  " ~ dist + target_len + target_freq + target_surp + trigger_len + trigger_freq + trigger_surp",
  
  " ~ dist + target_len + target_freq + target_surp + trigger_len + trigger_freq + trigger_surp + ppmi",
  " ~ dist + target_len + target_freq + target_surp + trigger_len + trigger_freq + trigger_surp + npmi",
  " ~ dist + target_len + target_freq + target_surp + trigger_len + trigger_freq + trigger_surp + ppmi + npmi",
  
  " ~ dist + target_len + target_freq + target_surp + trigger_len + trigger_freq + trigger_surp + e_ppmi",
  " ~ dist + target_len + target_freq + target_surp + trigger_len + trigger_freq + trigger_surp + e_npmi",
  " ~ dist + target_len + target_freq + target_surp + trigger_len + trigger_freq + trigger_surp + e_ppmi + e_npmi",
  
  " ~ dist + target_len + target_freq + target_surp + trigger_len + trigger_freq + trigger_surp + ppmi + npmi + e_ppmi + e_npmi"

)

regression_form_tags = c("Baseline", "NPMI", "PPMI", "PPMI+NPMI", "E[NPMI]", "E[PPMI]", "E[PPMI]+E[NPMI]", "All Predictors")

pred_df = data.frame()
coeff_df = data.frame()

langs = c("it", "tr", "de", "es", "fi")

for(i in c(1:length(regression_forms))) {

  for (l in langs){
    #for (m in models){

      form = regression_forms[i]
      tag = regression_form_tags[i]
      
      print(paste("<", l, tag, ">", sep="  "))
      
      result = model_cross_val_poisson(paste0("n_regressions", form), combined_df %>% filter(lang == l), lang = l, tag = tag)
      #result = model_cross_val_logistic(paste0("prop_subj", form), combined_df %>% filter(lang == l), lang = l, tag = tag)

      
      preds = data.frame(result[1]) %>%
        mutate(
          llh = - exp(pred) + y * pred - log(factorial(y)),
          tag = tag)
      
      pred_df = rbind(pred_df, preds %>% mutate(lang = l))
      coeff_df = rbind(coeff_df, data.frame(result[2]) %>% mutate(lang = l))

    #}
  }
}

#write.csv(pred_df, "./fits/agg_poisson_preds.csv")
#write.csv(coeff_df, "./fits/agg_poisson_coeffs.csv")

#write.csv(pred_df, "./fits/meco_logistic_preds.csv")
#write.csv(coeff_df, "./fits/meco_logistic_coeffs.csv")


```


```{r}

#pred_df = read.csv("./fits/agg_poisson_preds.csv")
#coeff_df = read.csv("./fits/agg_poisson_coeffs.csv")

#pred_df = read.csv("./fits/meco_logistic_preds.csv")
#coeff_df = read.csv("./fits/meco_logistic_coeffs.csv")

tags = unique(pred_df$tag)
dll_df = data.frame()

for (l in langs){
  temp_df = pred_df %>% filter(lang == l)
      
  for(tag1 in tags){
      
      if(tag1 != "Baseline"){
        
        dll1 = temp_df[temp_df$tag  == tag1,]$llh
        dll2 = temp_df[temp_df$tag  == "Baseline",]$llh
        dll_diff = dll1 - dll2
        dll_diff = dll_diff[!is.na(dll_diff)]
        ptest = perm.test(dll_diff, num.sim = 500)
        dll_df = rbind(dll_df, data.frame(dll_diff) %>% mutate(tag=tag1, lang = l, pval = as.numeric(ptest$p.value)))
      }
}
}

```




```{r}
# This block looks at the comparison of NPMI and E[NPMI] to see if the expectation is performing significantly better here
dll_npmi_comp = data.frame()
for (l in langs){
    temp_df = pred_df %>% filter(lang == l)
    dll1 = temp_df[temp_df$tag  == "E[NPMI]",]$llh
    dll2 = temp_df[temp_df$tag  == "NPMI",]$llh
    dll_diff = dll1 - dll2
    dll_diff = dll_diff[!is.na(dll_diff)]
    ptest = perm.test(dll_diff, num.sim = 500)
    dll_npmi_comp = rbind(dll_npmi_comp, data.frame(lang = l, npmi_m=mean(dll_diff), npmi_pval = as.numeric(ptest$p.value)))
}
dll_npmi_comp 
```

```{r}

plot_df = dll_df %>%
  drop_na() %>%
  mutate(theory = case_when(
    tag == "NPMI" | tag == "E[NPMI]" ~ "Reanalysis",
    tag == "PPMI" | tag == "E[PPMI]" ~ "Reactivation",
    is.na(tag) ~ "Ensemble"
  )) %>%
  mutate(tag = factor(tag, levels = c("PMI", "PPMI", "NPMI", "PPMI+NPMI",  "E[PMI]", "E[PPMI]", "E[NPMI]", "E[PPMI]+E[NPMI]", "All Predictors"))) %>%
  group_by(lang, tag, theory) %>%
    summarise(m = mean(dll_diff),
              s = std.error(dll_diff),
              upper = m + s * 1.96,
              lower = m - s * 1.96,
              pval = unique(pval)) %>%
  ungroup() %>%
  group_by(lang) %>%
    mutate(y_max = max(upper)) %>%
  ungroup()%>%
  mutate(y_step = max(upper) / 15) %>%
  merge(., dll_npmi_comp, by=c("lang"))

plot_df
```

```{r}
pval_func = function(pval) {
  if_else(pval >= 0.05 , " ",
          if_else(pval < 0.05 & pval >= 0.01, "*",
                  if_else(pval < 0.01 & pval >= 0.001, "**",
                          if_else(pval < 0.001,
                                  "***",""))))
}

```

```{r}

library(ggtext)
  
plot_df %>%
  mutate(lang = factor(lang, levels = c("de", "es", "fi", "it", "tr"),
         labels = c("German", "Spanish", "Finnish", "Italian", "Turkish"))) %>%
  mutate(sig = pval_func(pval),
         npmi_pval = pval_func(npmi_pval)) %>%
  ggplot(aes(x = tag, y=m, color = theory, fill = theory)) +
    #geom_point(size = 2) +
    geom_bar(stat="identity", alpha=0.5) +
    geom_errorbar(aes(ymax = upper, ymin = lower), width = 0) +
    geom_text(aes(label = sig, color = theory, y = y_max + y_step * 4), size = 3, angle = 0) +
  
    # NPMI vs. E[NPMI] Comparison plotting
    geom_segment(aes(y = y_max + 1 * y_step, yend = y_max + 1 * y_step), size =0.5, x = 1.95, xend = 5.05, color="gray", alpha=0.4) +
    geom_text(aes(label = npmi_pval, y = y_max + y_step * 1.5, x = 3.5), size = 3, angle = 0, color = "gray", alpha=0.2) +
  
  
    geom_hline(yintercept = 0, color = "black", linetype="dashed") +
    #geom_text(aes(label = ""), y=0.12, size = 1) +
    facet_wrap(.~lang, nrow=2) +
    #coord_cartesian(ylim=c(-0.03, 0.21)) +
    ylab("Delta LogLik") +
    labs(color="") +
    #scale_color_viridis(discrete = TRUE, option = "D") +
    #ggtitle("Regression Count Between Words") +
    scale_color_manual(values=c("#39ccbd", "#3991cc")) +
    scale_fill_manual(values=c("#39ccbd", "#3991cc")) +
    theme(
      axis.text.x = element_text(angle = 45, hjust = 1, size = 9),
      axis.title.x = element_blank(),
      axis.text.y = element_text(angle = 90, hjust = 0.5),
      legend.position = "none",
      panel.grid.minor = element_blank()
    )

ggsave("./images/meco_results.pdf", device="pdf", width = 8, height = 5)

```



## ============
## Coefficients 
## =============

```{r}

coeff_agg_df = coeff_df %>%
  filter(term != "(Intercept)") %>%
  group_by(term, lang) %>%
    summarise(
      m = mean(estimate), s = std.error(estimate),
      upper = m + 1.96 * s, lower = m - 1.96 * s
    ) %>%
  ungroup() %>%
  mutate(f1 = if_else(term %in% c("freq", "len", "surp"), 1, 0),
         f2 = if_else(tag == "Baseline", 1, 0),
         x = if_else(f1 == 1 & f2 == 0, 1, 0)) %>%
  filter(x != 1) %>%
  dplyr::select(-f1, -f2, -x)


coeff_agg_df %>%
  #mutate(ci = s * 1.96) %>%
  #filter(term != "dist") %>%
  #mutate(term = factor(term, levels = c("freq", "len", "surp", "max_surp", "max_pmi", "max_topkj", "max_topkji", "max_kld"), labels = c("Frequency", "Length", "Surprisal", "Max Surprisal", "Max PMI", "Max Top-K↑", "Max Top-k↓", "Max KLD"))) %>%
  mutate(lang = factor(lang, levels = c("de", "es", "fi", "it", "tr"),
         labels = c("German", "Spanish", "Finnish", "Italian", "Turkish"))) %>%
  mutate(term = factor(term, levels = c("ppmi", "npmi", "e_ppmi", "e_npmi", "target_freq", "target_len", "target_surp", "trigger_freq", "trigger_len", "trigger_surp", "dist"),
         labels = c("PPMI", "NPMI", "E[PPMI]", "E[NPMI]", "Frequency\n(Target)", "Length\n(Target)", "Surprisal\n(Target)", "Frequency\n(Source)", "Length\n(Source)", "Surprisal\n(Source)", "Distance" ))) %>%
  ggplot(aes(x = lang, y = m, color = lang, fill = lang)) +
    geom_hline(yintercept = 0, color = "blue", alpha = 0.5, linetype = "dotted") +
    geom_bar(stat = "identity", alpha=0.5, width = 0.7, position = position_dodge(width = 0.9)) + 
    geom_errorbar(aes(ymin = lower, ymax = upper), width = 0, position = position_dodge(width = 0.9)) +
    ylab("Coefficient Estimate") +
    xlab("") +
  #scale_color_brewer( palette = "Set3") +
  facet_grid(.~term, scales = "free_y") +
  labs (color="", fill="") +
  theme(
    strip.text.x = element_text(angle = 45),
    axis.text.x = element_blank(),
    #axis.text.x = element_text(angle = 45, hjust = 1),
    legend.position = "bottom"
  )

ggsave("./images/meco_coeffs.pdf", device = "pdf", width = 9 , height = 4)


```








