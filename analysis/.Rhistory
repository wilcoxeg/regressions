for(i in c(1:length(regression_forms))) {
form = regression_forms[i]
tag = regression_form_tags[i]
result = model_cross_val_linear(form, df, dvar=n_regression)
estimates = data.frame(result[1]) %>% mutate(model = tag)
coeff_list = c(coeff_list, result[2])
}
regression_forms = c(
"n_regressions ~ target_len + target_surp + dist",
"n_regressions ~ target_len + target_surp + dist + pmi",
"n_regressions ~ target_len + target_surp + dist + topk",
"n_regressions ~ target_len + target_surp + dist + kld",
"n_regressions ~ target_len + target_surp + dist + pmi + topk + kld"
)
regression_form_tags = c("baseline", "pmi", "topk", "kld", "all")
accuracy_df = data.frame()
coeff_list = c()
for(i in c(1:length(regression_forms))) {
form = regression_forms[i]
tag = regression_form_tags[i]
result = model_cross_val_linear(form, df, n_regressions)
estimates = data.frame(result[1]) %>% mutate(model = tag)
coeff_list = c(coeff_list, result[2])
}
regression_forms = c(
"n_regressions ~ target_len + target_surp + dist",
"n_regressions ~ target_len + target_surp + dist + pmi",
"n_regressions ~ target_len + target_surp + dist + topk",
"n_regressions ~ target_len + target_surp + dist + kld",
"n_regressions ~ target_len + target_surp + dist + pmi + topk + kld"
)
regression_form_tags = c("baseline", "pmi", "topk", "kld", "all")
accuracy_df = data.frame()
coeff_list = c()
for(i in c(1:length(regression_forms))) {
form = regression_forms[i]
tag = regression_form_tags[i]
result = model_cross_val_linear(form, df, "n_regressions")
estimates = data.frame(result[1]) %>% mutate(model = tag)
coeff_list = c(coeff_list, result[2])
}
coeff_list
model_cross_val_linear = function(form, df, d_var, num_folds=10){
folds <- cut(seq(1,nrow(df)),breaks=num_folds,labels=FALSE)
estimates = data.frame()
models <- data.frame()
for(i in 1:num_folds){
testIndexes = which(folds==i,arr.ind=TRUE)
testData = df[testIndexes,]
trainData = df[-testIndexes,]
model = lm(as.formula(form), data = trainData)
stdev = sigma(model)
densities <- data.frame(log(dnorm(testData[[d_var]], mean=predict(model, newdata=testData), sd=stdev)))
estimates = rbind(estimates, densities)
models = rbind(models, model$coefficients )
}
result = list(estimates, models)
return( result )
}
model_cross_val_linear = function(form, df, d_var, num_folds=10){
folds <- cut(seq(1,nrow(df)),breaks=num_folds,labels=FALSE)
estimates = data.frame()
models <- data.frame()
for(i in 1:num_folds){
testIndexes = which(folds==i,arr.ind=TRUE)
testData = df[testIndexes,]
trainData = df[-testIndexes,]
model = lm(as.formula(form), data = trainData)
stdev = sigma(model)
densities <- data.frame(log(dnorm(testData[[d_var]], mean=predict(model, newdata=testData), sd=stdev)))
estimates = rbind(estimates, densities)
models = rbind(models, model$coefficients )
}
result = list(estimates, models)
return( result )
}
regression_forms = c(
"n_regressions ~ target_len + target_surp + dist",
"n_regressions ~ target_len + target_surp + dist + pmi",
"n_regressions ~ target_len + target_surp + dist + topk",
"n_regressions ~ target_len + target_surp + dist + kld",
"n_regressions ~ target_len + target_surp + dist + pmi + topk + kld"
)
regression_form_tags = c("baseline", "pmi", "topk", "kld", "all")
accuracy_df = data.frame()
coeff_list = c()
for(i in c(1:length(regression_forms))) {
form = regression_forms[i]
tag = regression_form_tags[i]
result = model_cross_val_linear(form, df, "n_regressions")
estimates = data.frame(result[1]) %>% mutate(model = tag)
coeff_list = c(coeff_list, result[2])
}
regression_forms = c(
"n_regressions ~ target_len + target_surp + dist",
"n_regressions ~ target_len + target_surp + dist + pmi",
"n_regressions ~ target_len + target_surp + dist + topk",
"n_regressions ~ target_len + target_surp + dist + kld",
"n_regressions ~ target_len + target_surp + dist + pmi + topk + kld"
)
regression_form_tags = c("baseline", "pmi", "topk", "kld", "all")
loglik_df = data.frame()
coeff_list = c()
for(i in c(1:length(regression_forms))) {
form = regression_forms[i]
tag = regression_form_tags[i]
result = model_cross_val_linear(form, df, "n_regressions")
estimates = data.frame(result[1]) %>% mutate(model = tag)
loglik_df = rbind(loglik_df, estimates)
coeff_list = c(coeff_list, result[2])
}
loglik_df
names(loglik_df) = c("loglik", "model")
loglik_df
loglik_df %>%
group_by(model) %>%
summarise(
m = mean(loglik),
s = std.error(loglik),
upper = m + s * 1.96,
lower = m - s * 1.96
) %>%
ungroup() %>%
ggplot(aes(x = model, y = m)) +
geom_point() +
geom_errorbar(aes(ymin=lower, ymax=upper))
loglik_df %>%
group_by(model) %>%
summarise(
m = mean(loglik),
s = std.error(loglik),
upper = m + s * 1.96,
lower = m - s * 1.96
)
loglik_df %>%
drop_na() %>%
group_by(model) %>%
summarise(
m = mean(loglik),
s = std.error(loglik),
upper = m + s * 1.96,
lower = m - s * 1.96
) %>%
ungroup() %>%
ggplot(aes(x = model, y = m)) +
geom_point() +
geom_errorbar(aes(ymin=lower, ymax=upper))
loglik_df %>%
drop_na() %>%
group_by(model) %>%
summarise(
m = mean(loglik),
s = std.error(loglik),
upper = m + s * 1.96,
lower = m - s * 1.96
)
loglik_df
loglik_df
loglik_df %>%
drop_na()
loglik_df %>%
drop_na() %>%
filter(loglik > -1000)
loglik_df %>%
drop_na() %>%
filter(loglik > -1000) %>%
group_by(model) %>%
summarise(
m = mean(loglik),
s = std.error(loglik),
upper = m + s * 1.96,
lower = m - s * 1.96
) %>%
ungroup() %>%
ggplot(aes(x = model, y = m)) +
geom_point() +
geom_errorbar(aes(ymin=lower, ymax=upper))
loglik_df %>%
drop_na() %>%
filter(loglik > -Inf) %>%
group_by(model) %>%
summarise(
m = mean(loglik),
s = std.error(loglik),
upper = m + s * 1.96,
lower = m - s * 1.96
) %>%
ungroup() %>%
ggplot(aes(x = model, y = m)) +
geom_point() +
geom_errorbar(aes(ymin=lower, ymax=upper))
loglik_test_df = loglik_df
loglik_test_df
loglik_test_df = loglik_df[0:100]
loglik_test_df = loglik_df[, 0:100]
loglik_test_df = loglik_df.head()
loglik_test_df = head(loglik_df)
loglik_test_df
loglik_test_df %>%
spread(loglik, model)
loglik_test_df %>%
spread(model, loglik)
baseline_logliks = loglik_df %>% filter(model == "baseline")
topk_logliks = loglik_df %>% filter(model == "topk")
t.test(baselin_logliks, topk_logliks)
t.test(baseline_logliks, topk_logliks)
baseline_logliks
t.test(baseline_logliks$loglik, topk_logliks$loglik)
baseline_logliks = loglik_df %>% filter(model == "baseline")
topk_logliks = loglik_df %>% filter(model == "topk")
t.test(baseline_logliks$loglik, topk_logliks$loglik)
topk_logliks
baseline_logliks
baseline_logliks$loglik
t.test(baseline_logliks$loglik, topk_logliks$loglik)
t.test(baseline_logliks$loglik, 0)
t.test(baseline_logliks$loglik)
t.test(baseline_logliks$loglik, topk_logliks$loglik)
topk_logliks$loglik
baseline_logliks$loglik
loglik_df %>%
drop_na() %>%
filter(loglik > -Inf) %>%
group_by(model) %>%
summarise(
m = mean(loglik),
s = std.error(loglik),
upper = m + s * 1.96,
lower = m - s * 1.96
) %>%
ungroup() %>%
ggplot(aes(x = model, y = m)) +
geom_point() +
geom_errorbar(aes(ymin=lower, ymax=upper))
m = loglik_df %>%
filter(model == "baseline" | model == "topk") %>%
lm(loglik ~ model)
m = loglik_df %>%
filter(model == "baseline" | model == "topk") %>%
lm(loglik ~ model, data = .)
loglik_df = loglik_df %>% filter(loglik > -Inf)
baseline_logliks = loglik_df %>% filter(model == "baseline")
topk_logliks = loglik_df %>% filter(model == "topk")
t.test(baseline_logliks$loglik, topk_logliks$loglik)
m = loglik_df %>%
filter(model == "baseline" | model == "topk") %>%
lm(loglik ~ model, data = .)
summary(m)
regress_df = read.csv("../data/regression_df.csv") %>% dplyr::select(-X) %>%
mutate(regression = if_else(n_subj > 0, T, F),
is_multitok = as.logical(is_multitok))
regress_df_pos = regress_df %>% filter(regression == T) %>% filter(is_multitok == F)
#regress_df_neg = sample_n(regress_df %>% filter(regression == F, is_multitok == F), nrow(regress_df_pos))
regress_df_neg = regress_df %>% filter(regression == F, is_multitok == F)
df = rbind(regress_df_pos, regress_df_neg) %>%
mutate(dist = trigger_ia_idx - target_ia_idx,
trigger_len = nchar(trigger),
target_len = nchar(target))
shhh <- suppressPackageStartupMessages # It's a library, so shhh!
shhh(library( mgcv ))
shhh(library(dplyr))
shhh(library(ggplot2))
shhh(library(lme4))
shhh(library(tidymv))
shhh(library(gamlss))
shhh(library(gsubfn))
shhh(library(lmerTest))
shhh(library(tidyverse))
shhh(library(boot))
shhh(library(rsample))
shhh(library(plotrix))
shhh(library(ggrepel))
shhh(library(mgcv))
theme_set(theme_bw())
options(digits=4)
options(dplyr.summarise.inform = FALSE)
set.seed(444)
langs = c("du", "en", "fi", "ge", "gr", "he", "it", "ko", "sp", "tr", "ru")
psychometrics = c("total_rt", "gaze_rt", "firstfix_rt")
contexts = c("short", "long")
lang_exposure = data.frame( lang = c("du", "en", "fi", "ge", "gr", "he", "it", "ko", "ru", "sp", "tr"  ),
ntoks = c(15.96, 41.21, 2.99, 40.37, 3.61, 0.69, 32.94, 6.28, 39.39, 24.45, 22.52 ))
dll_df = dll_xlang_surp_df %>%
merge(lang_exposure, by = "lang") %>%
filter(comp == "0")
model_cross_val = function(form, df, d_var, num_folds=10){
folds <- cut(seq(1,nrow(df)),breaks=num_folds,labels=FALSE)
estimates <- c()
models <- c()
for(i in 1:num_folds){
testIndexes = which(folds==i,arr.ind=TRUE)
testData = df[testIndexes,]
trainData = df[-testIndexes,]
model = lm(as.formula(form), data = trainData)
stdev = sigma(model)
densities <- log(dnorm(testData[[d_var]],
mean=predict(model, newdata=testData),
sd=stdev))
estimates <- c(estimates, densities)
}
return(estimates)
}
regression_names = c("bl", "0", "1", "2")
# "bl" = baseline model with full surprisals, 0 = surprisal dropped at slot 0 i.e. the current word
dll_xlang_surp_df = data.frame()
for (lang in langs) {
print(paste0("Fitting model for ", lang))
df = read.csv(paste0("./cleaned_data/l1/", lang, "_clean_data.csv")) %>%
filter(context == "long")
for (psychometric in psychometrics) {
regression_forms = c(
paste0(psychometric, " ~ surp + prev_surp + prev2_surp + freq*len + prev_freq*prev_len + prev2_freq*prev2_len"),
paste0(psychometric, " ~ prev_surp + prev2_surp + freq*len + prev_freq*prev_len + prev2_freq*prev2_len"),
paste0(psychometric, " ~ surp + prev2_surp + freq*len + prev_freq*prev_len + prev2_freq*prev2_len"),
paste0(psychometric, " ~ surp + prev_surp + freq*len + prev_freq*prev_len + prev2_freq*prev2_len")
)
loglik_df = data.frame(names=regression_names, forms=regression_forms) %>%
mutate(logliks = map(regression_forms, model_cross_val, df=df, d_var=psychometric )) %>%
dplyr::select(-forms)
dlls = list()
dll_df = data.frame()
for (i in regression_names){
ll1 = loglik_df[loglik_df["names"] == "bl"][2][[1]]
ll2 = loglik_df[loglik_df["names"] == i][2][[1]]
dll = ll1 - ll2
dll = dll[!is.na(dll)]
ttest = t.test(dll)
dll_df = rbind(dll_df, data.frame(comp = i, mean = mean(dll),
upper = mean(dll) + (1.96 * std.error(dll)), lower = mean(dll) - (1.96 * std.error(dll)),
ttest_pval = ttest$p.value, ttest_est = ttest$estimate))
}
dll_xlang_surp_df = rbind(dll_xlang_surp_df, dll_df %>% mutate(lang = lang, psychometric = psychometric))
}
}
lang_exposure = data.frame( lang = c("du", "en", "fi", "ge", "gr", "he", "it", "ko", "ru", "sp", "tr"  ),
ntoks = c(15.96, 41.21, 2.99, 40.37, 3.61, 0.69, 32.94, 6.28, 39.39, 24.45, 22.52 ))
dll_df = dll_xlang_surp_df %>%
merge(lang_exposure, by = "lang") %>%
filter(comp == "0")
cor.test(dll_df$mean, dll_df$ntoks)
dll_df %>%
ggplot(aes(x=ntoks, y = mean, label = lang)) +
geom_smooth(method = "lm") +
geom_point(size = 2) +
geom_errorbar(aes(ymin=lower, ymax=upper), width = 0.3) +
geom_label_repel() +
ylab("ΔLogLiklihood (per word)") +
xlab("# of Training Tokens (Billion)") +
ggtitle("# Training Tokens vs. ΔLL")
ggsave("./images/dll_vs_training-size.png", width = 4, height = 4)
dll_df
lang_exposure = data.frame( lang = c("du", "en", "fi", "ge", "gr", "he", "it", "ko", "ru", "sp", "tr"  ),
ntoks = c(15.96, 41.21, 2.99, 40.37, 3.61, 0.69, 32.94, 6.28, 39.39, 24.45, 22.52 ))
dll_df = dll_xlang_surp_df %>%
merge(lang_exposure, by = "lang") %>%
filter(comp == "0") %>%
cor.test(dll_df$mean, dll_df$ntoks)
lang_exposure = data.frame( lang = c("du", "en", "fi", "ge", "gr", "he", "it", "ko", "ru", "sp", "tr"  ),
ntoks = c(15.96, 41.21, 2.99, 40.37, 3.61, 0.69, 32.94, 6.28, 39.39, 24.45, 22.52 ))
dll_df = dll_xlang_surp_df %>%
merge(lang_exposure, by = "lang") %>%
filter(comp == "0")
cor.test(dll_df$mean, dll_df$ntoks)
dll_df %>%
ggplot(aes(x=ntoks, y = mean, label = lang, color = psychometric)) +
geom_smooth(method = "lm") +
geom_point(size = 2) +
geom_errorbar(aes(ymin=lower, ymax=upper), width = 0.3) +
geom_label_repel() +
ylab("ΔLogLiklihood (per word)") +
xlab("# of Training Tokens (Billion)") +
ggtitle("# Training Tokens vs. ΔLL")
ggsave("./images/dll_vs_training-size.png", width = 4, height = 4)
dll_df
lang_exposure = data.frame( lang = c("du", "en", "fi", "ge", "gr", "he", "it", "ko", "ru", "sp", "tr"  ),
ntoks = c(15.96, 41.21, 2.99, 40.37, 3.61, 0.69, 32.94, 6.28, 39.39, 24.45, 22.52 ))
dll_df = dll_xlang_surp_df %>%
filter(psychometric == "gaze_rt") %>%
merge(lang_exposure, by = "lang") %>%
filter(comp == "0")
cor.test(dll_df$mean, dll_df$ntoks)
dll_df %>%
ggplot(aes(x=ntoks, y = mean, label = lang)) +
geom_smooth(method = "lm") +
geom_point(size = 2) +
geom_errorbar(aes(ymin=lower, ymax=upper), width = 0.3) +
geom_label_repel() +
ylab("ΔLogLiklihood (per word)") +
xlab("# of Training Tokens (Billion)") +
ggtitle("# Training Tokens vs. ΔLL")
ggsave("./images/dll_vs_training-size.png", width = 4, height = 4)
lang_ppl = data.frame( lang = c("du", "en", "fi", "ge", "gr", "he", "it", "ko", "ru", "sp", "tr"  ),
ppl = c(8.78, 16.40, 15.05, 10.88, 7.56, 11.01, 10.53,  10.92, 9.15, 12.93, 9.79 ))
lang_ppl_df = dll_xlang_surp_df %>%
merge(lang_ppl, by = "lang") %>%
filter(comp == "0", psychometric == "gaze_rt")
cor.test(lang_ppl_df$mean, lang_ppl_df$ppl)
lang_ppl_df %>%
ggplot(aes(x=ppl, y = mean, label = lang)) +
geom_smooth(method = "lm") +
geom_point(size = 2) +
geom_errorbar(aes(ymin=lower, ymax=upper), width = 0.3) +
geom_label_repel() +
ylab("ΔLogLiklihood (per word)") +
xlab("Test Perplexity")
ggsave("./images/dll_vs_ppl.png", width = 4, height = 4)
lang_exposure = data.frame( lang = c("du", "en", "fi", "ge", "gr", "he", "it", "ko", "ru", "sp", "tr"  ),
ntoks = c(15.96, 41.21, 2.99, 40.37, 3.61, 0.69, 32.94, 6.28, 39.39, 24.45, 22.52 ))
dll_df = dll_xlang_surp_df %>%
filter(psychometric == "gaze_rt") %>%
merge(lang_exposure, by = "lang") %>%
filter(comp == "0")
cor.test(dll_df$mean, dll_df$ntoks)
dll_df %>%
ggplot(aes(x=ntoks, y = mean, label = lang)) +
geom_smooth(method = "lm") +
geom_point(size = 2) +
geom_errorbar(aes(ymin=lower, ymax=upper), width = 0.3) +
geom_label_repel() +
ylab("ΔLogLiklihood (per word)") +
xlab("# of Training Tokens (Billion)") #+
#ggtitle("# Training Tokens vs. ΔLL")
ggsave("./images/dll_vs_training-size.png", width = 4, height = 4)
non_linear_delta_df = data.frame()
for(lang in langs) {
for(ctext in contexts) {
df = read.csv(paste0("./cleaned_data/l1/", lang, "_clean_data.csv")) %>% filter(context == ctext) %>% rename(psychometric = gaze_rt)
median_surp = median(df$surp)
high_surp = df %>% filter(surp >= median_surp)
low_surp = df %>% filter(surp < median_surp)
high_lm = lm(psychometric ~ surp + len + freq + prev_surp + prev_len + prev_freq, data =  high_surp)
b_high = high_lm$coefficients[2]
summary(high_lm)
low_lm = lm(psychometric ~ surp + len + freq + prev_surp + prev_len + prev_freq, data =  low_surp)
b_low = low_lm$coefficients[2]
delta = b_high - b_low
delta_df = data_frame(delta = delta, lang = lang, context=ctext)
non_linear_delta_df = rbind(non_linear_delta_df, delta_df)
}
}
lang_ppl = data.frame( lang = c("du", "en", "fi", "ge", "gr", "he", "it", "ko", "ru", "sp", "tr"  ),
ppl = c(8.78, 16.40, 15.05, 10.88, 7.56, 11.01, 10.53,  10.92, 9.15, 12.93, 9.79 ))
linearity_df = non_linear_delta_df %>%
merge(lang_ppl, by = c("lang"))
linearity_df %>%
mutate(context = if_else(context == "short", "Short Context", "Long Context")) %>%
ggplot(aes(x = ppl, y = delta)) +
stat_smooth(method = "lm") +
geom_hline(aes(yintercept = 0), color = "orange", linetype = "dashed") +
geom_point() +
geom_label_repel(aes(label = lang)) +
facet_wrap(~context)+
ylab("Superlinearity") +
xlab("Perplexity")
ggsave("./images/superlinearity.png", width = 6, height = 3)
lang_ppl = data.frame( lang = c("du", "en", "fi", "ge", "gr", "he", "it", "ko", "ru", "sp", "tr"  ),
ppl = c(8.78, 16.40, 15.05, 10.88, 7.56, 11.01, 10.53,  10.92, 9.15, 12.93, 9.79 ))
linearity_df = non_linear_delta_df %>%
merge(lang_ppl, by = c("lang"))
linearity_df %>%
mutate(context = if_else(context == "short", "Short Context", "Long Context")) %>%
ggplot(aes(x = ppl, y = delta)) +
stat_smooth(method = "lm") +
geom_hline(aes(yintercept = 0), color = "orange", linetype = "dashed") +
geom_point() +
geom_label_repel(aes(label = lang)) +
facet_wrap(context~)+
lang_ppl = data.frame( lang = c("du", "en", "fi", "ge", "gr", "he", "it", "ko", "ru", "sp", "tr"  ),
ppl = c(8.78, 16.40, 15.05, 10.88, 7.56, 11.01, 10.53,  10.92, 9.15, 12.93, 9.79 ))
linearity_df = non_linear_delta_df %>%
merge(lang_ppl, by = c("lang"))
linearity_df %>%
mutate(context = if_else(context == "short", "Short Context", "Long Context")) %>%
ggplot(aes(x = ppl, y = delta)) +
stat_smooth(method = "lm") +
geom_hline(aes(yintercept = 0), color = "orange", linetype = "dashed") +
geom_point() +
geom_label_repel(aes(label = lang)) +
facet_wrap(context~.)+
ylab("Superlinearity") +
xlab("Perplexity")
ggsave("./images/superlinearity.png", width = 3, height = 6)
lang_ppl = data.frame( lang = c("du", "en", "fi", "ge", "gr", "he", "it", "ko", "ru", "sp", "tr"  ),
ppl = c(8.78, 16.40, 15.05, 10.88, 7.56, 11.01, 10.53,  10.92, 9.15, 12.93, 9.79 ))
linearity_df = non_linear_delta_df %>%
merge(lang_ppl, by = c("lang"))
linearity_df %>%
mutate(context = if_else(context == "short", "Short Context", "Long Context")) %>%
ggplot(aes(x = ppl, y = delta)) +
stat_smooth(method = "lm") +
geom_hline(aes(yintercept = 0), color = "orange", linetype = "dashed") +
geom_point() +
geom_label_repel(aes(label = lang)) +
facet_grid(context~.)+
ylab("Superlinearity") +
xlab("Perplexity")
ggsave("./images/superlinearity.png", width = 3, height = 6)
lang_ppl = data.frame( lang = c("du", "en", "fi", "ge", "gr", "he", "it", "ko", "ru", "sp", "tr"  ),
ppl = c(8.78, 16.40, 15.05, 10.88, 7.56, 11.01, 10.53,  10.92, 9.15, 12.93, 9.79 ))
linearity_df = non_linear_delta_df %>%
merge(lang_ppl, by = c("lang"))
linearity_df %>%
mutate(context = if_else(context == "short", "Short Context", "Long Context")) %>%
ggplot(aes(x = ppl, y = delta)) +
stat_smooth(method = "lm") +
geom_hline(aes(yintercept = 0), color = "orange", linetype = "dashed") +
geom_point() +
geom_label_repel(aes(label = lang)) +
facet_grid(context~.)+
ylab("Superlinearity") +
xlab("Perplexity")
ggsave("./images/superlinearity.png", width = 3, height = 5)
