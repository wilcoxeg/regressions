---
title: "Regressions: Analysis"
output: html_notebook
---

```{r}
shhh <- suppressPackageStartupMessages # It's a library, so shhh!

shhh(library( mgcv ))
shhh(library(dplyr))
shhh(library(ggplot2))
shhh(library(lme4))
shhh(library(tidymv))
shhh(library(gamlss))
shhh(library(gsubfn))
shhh(library(lmerTest))
shhh(library(tidyverse))
shhh(library(boot))
shhh(library(rsample))
shhh(library(plotrix))
shhh(library(ggrepel))
shhh(library(mgcv))
shhh(library(Hmisc))
shhh(library(jmuOutlier))


#options(JULIA_HOME = "/Applications/Julia-1.8.app/Contents/Resources/julia/bin/")
#library(jglmm)
#jglmm_setup()


theme_set(theme_bw())
options(digits=4)
options(dplyr.summarise.inform = FALSE)
set.seed(444)
options(scipen=999)
corpora = c("provo", "ucl", "dundee")
models = c("BERT-allRC", "BERT-maskRC", "BERT-dropRC")
```


# Read and Clean Data

```{r}

provo_pairwise_df = read.csv("../data/harmonized_results/provo_pairwise_stats_df.csv")
provo_sacc_df = read.csv("../data/harmonized_results/provo_saccades_df.csv")

provo_agg_regressions = provo_sacc_df %>%
  mutate(next_ia_idx = as.numeric(next_ia_idx), prev_ia_idx = as.numeric(prev_ia_idx)) %>%
  drop_na() %>%
  filter(next_ia_idx < curr_ia_idx) %>%
  group_by(text_id, sent_id, curr_ia_idx, next_ia_idx) %>%
    summarise(n_regressions = n(), n_subjs = length(unique(subj))) %>%
  ungroup() %>%
  rename(
    trigger_idx = curr_ia_idx,
    target_idx = next_ia_idx
  )
  
provo_df = provo_pairwise_df %>%
  merge(provo_agg_regressions, all= T, by=c("text_id", "sent_id", "trigger_idx", "target_idx")) %>%
  mutate(corpus = "provo") %>%
  rename(model = mask_type) %>%
  mutate(model = case_when(model == "none" ~ "BERT-allRC", model == "mask" ~ "BERT-maskRC", model == "truncate" ~ "BERT-dropRC"))

```

```{r}

ucl_pairwise_df = read.csv("../data/harmonized_results/ucl_pairwise_stats_df.csv")
ucl_sacc_df = read.csv("../data/harmonized_results/ucl_saccades_df.csv")

ucl_agg_regressions = ucl_sacc_df %>%
  mutate(next_ia_idx = as.numeric(next_ia_idx), prev_ia_idx = as.numeric(prev_ia_idx)) %>%
  drop_na() %>%
  filter(next_ia_idx < curr_ia_idx) %>%
  group_by(text_id, sent_id, curr_ia_idx, next_ia_idx) %>%
    summarise(n_regressions = n(), n_subjs = length(unique(subj))) %>%
  ungroup() %>%
  rename(
    trigger_idx = curr_ia_idx,
    target_idx = next_ia_idx
  )
  
ucl_df = ucl_pairwise_df %>%
  merge(ucl_agg_regressions, all= T, by=c("text_id", "sent_id", "trigger_idx", "target_idx")) %>%
  mutate(corpus = "ucl")%>%
  mutate(ppmi = if_else(pmi > 0, pmi, 0),
         npmi = if_else(pmi < 0, pmi, 0)) %>%
  rename(model = mask_type) %>%
  mutate(model = case_when(model == "none" ~ "BERT-allRC", model == "mask" ~ "BERT-maskRC", model == "truncate" ~ "BERT-dropRC"))
  

```

```{r}

dundee_pairwise_df = read.csv("../data/harmonized_results/dundee_pairwise_stats_df.csv")
dundee_sacc_df = read.csv("../data/harmonized_results/dundee_saccades_df.csv")

dundee_agg_regressions = dundee_sacc_df %>%
  mutate(next_ia_idx = as.numeric(next_ia_idx), prev_ia_idx = as.numeric(prev_ia_idx)) %>%
  drop_na() %>%
  filter(next_ia_idx < curr_ia_idx) %>%
  group_by(text_id, sent_id, curr_ia_idx, next_ia_idx) %>%
    summarise(n_regressions = n(), n_subjs = length(unique(subj))) %>%
  ungroup() %>%
  rename(
    trigger_idx = curr_ia_idx,
    target_idx = next_ia_idx
  )
  
dundee_df = dundee_pairwise_df %>%
  merge(dundee_agg_regressions, all= T, by=c("text_id", "sent_id", "trigger_idx", "target_idx")) %>%
  mutate(corpus = "dundee")%>%
  mutate(ppmi = if_else(pmi > 0, pmi, 0),
         npmi = if_else(pmi < 0, pmi, 0)) %>%
  rename(model = mask_type) %>%
  mutate(model = case_when(model == "none" ~ "BERT-allRC", model == "mask" ~ "BERT-maskRC", model == "truncate" ~ "BERT-dropRC"))
# Currently, this includes information for when regressions happen in text IDs 4-n. Drop this below
  

```

```{r}

combined_df = data.frame()
combined_df = rbind(combined_df, provo_df)
combined_df = rbind(combined_df, ucl_df)
combined_df = rbind(combined_df, dundee_df)
combined_df = combined_df %>%
  mutate(n_regressions = if_else(is.na(n_regressions), 0, as.double(n_regressions)),
         n_subjs = if_else(is.na(n_subjs), 0, as.double(n_subjs)),
         target_len = scale(target_len),
         target_freq = scale(target_freq),
         target_surp = scale(target_surp),
         trigger_surp = scale(trigger_surp),
         trigger_len = scale(trigger_len),
         trigger_freq = scale(trigger_freq),
         
         pmi = scale(pmi),
         ppmi = scale(ppmi),
         npmi = scale(npmi), # So 
         e_pmi = scale(e_pmi),
         e_ppmi = scale(e_ppmi),
         e_npmi = scale(-1 *  e_npmi),
         dist = scale(trigger_idx - target_idx)) %>%
  mutate(prop_subj = case_when(
    corpus == "ucl" ~ n_subjs / 43,
    corpus == "provo" ~ n_subjs / 84,
    corpus == "dundee" ~ n_subjs / 10
  )) %>%
  drop_na()
combined_df

```

```{r}

combined_df %>%
  mutate(pmi_sign = if_else(pmi > 0, "Pos", "Neg")) %>%
  group_by(corpus, pmi_sign) %>%
    summarise(n = n()) %>%
  ungroup()

combined_df %>%
  drop_na() %>%
  ggplot(aes(x=pmi, y=prop_subj)) +
    stat_smooth() +
    coord_cartesian(ylim = c(0, 0.09)) +
    ylab("Proportion of Subjects who Regress") +
    xlab("PMI Between Word Pair") +
    facet_grid(model~corpus)

```


## Logistic Regression Analysis
```{r}

m_pmi = combined_df %>%
  filter(model == "BERT-maskRC", corpus == "provo") %>%
  glm("n_regressions ~ dist + target_len + target_freq + target_surp + trigger_len + trigger_freq + trigger_surp + pmi + e_pmi", data = ., family = poisson())
summary(m_pmi)

m_pmi = combined_df %>%
  filter(model == "BERT-dropRC", corpus == "provo") %>%
  glm("n_regressions ~ dist + target_len + target_freq + target_surp + trigger_len + trigger_freq + trigger_surp + pmi + e_pmi", data = ., family = poisson())
summary(m_pmi)

```


```{r}

model_cross_val_poisson = function(form, df, corpus, tag, num_folds=10){
  
  folds <- cut(seq(1,nrow(df)),breaks=num_folds,labels=FALSE)
  
  estimates = data.frame()
  coeffs = data.frame()
  for(i in 1:num_folds){
    testIndexes = which(folds==i,arr.ind=TRUE)
    testData = df[testIndexes,]
    trainData = df[-testIndexes,]

    model = glm(as.formula(form), data = trainData, family = poisson())
    
    preds = testData %>% dplyr::select(n_regressions) %>% rename(y=n_regressions) %>% 
      mutate(pred = predict(model, newdata = testData)) %>% 
      mutate(fold = i)

    estimates = rbind(estimates, preds)
    coeffs = rbind(coeffs, tidy(model) %>% mutate(corpus = corpus, tag = tag, fold = i ) )
  }

  result = list(estimates, coeffs)
  return( result )
}

```


```{r, warning=FALSE}

model_cross_val_logistic = function(form, df, corpus, tag, num_folds=10){
  
  folds <- cut(seq(1,nrow(df)),breaks=num_folds,labels=FALSE)
  
  estimates = data.frame()
  coeffs = data.frame()
  for(i in 1:num_folds){
    testIndexes = which(folds==i,arr.ind=TRUE)
    testData = df[testIndexes,]
    trainData = df[-testIndexes,]

    model = glm(as.formula(form), data = trainData, family = "quasibinomial")
    
    preds = testData %>% dplyr::select(prop_subj) %>% rename(y=prop_subj) %>% 
      mutate(pred = predict(model, newdata = testData)) %>% 
      mutate(fold = i)

    estimates = rbind(estimates, preds)
    coeffs = rbind(coeffs, tidy(model) %>% mutate(corpus = corpus, tag = tag, fold = i ) )
  }

  result = list(estimates, coeffs)
  return( result )
}

```

```{r, include = FALSE}

regression_forms = c(
  " ~ dist + target_len + target_freq + target_surp + trigger_len + trigger_freq + trigger_surp",
  
  " ~ dist + target_len + target_freq + target_surp + trigger_len + trigger_freq + trigger_surp + ppmi",
  " ~ dist + target_len + target_freq + target_surp + trigger_len + trigger_freq + trigger_surp + npmi",
  " ~ dist + target_len + target_freq + target_surp + trigger_len + trigger_freq + trigger_surp + ppmi + npmi",
  
  " ~ dist + target_len + target_freq + target_surp + trigger_len + trigger_freq + trigger_surp + e_ppmi",
  " ~ dist + target_len + target_freq + target_surp + trigger_len + trigger_freq + trigger_surp + e_npmi",
  " ~ dist + target_len + target_freq + target_surp + trigger_len + trigger_freq + trigger_surp + e_ppmi + e_npmi",
  
  " ~ dist + target_len + target_freq + target_surp + trigger_len + trigger_freq + trigger_surp + ppmi + npmi + e_ppmi + e_npmi"

)

regression_form_tags = c("Baseline", "NPMI", "PPMI", "PPMI+NPMI", "E[NPMI]", "E[PPMI]", "E[PPMI]+E[NPMI]", "All Predictors")

pred_df = data.frame()
coeff_df = data.frame()

for(i in c(1:length(regression_forms))) {

  for (c in corpora){
    for (m in models){

      form = regression_forms[i]
      tag = regression_form_tags[i]
      
      print(paste("<", c, m, tag, ">", sep="  "))
      
      #result = model_cross_val_poisson(paste0("n_regressions", form), combined_df %>% filter(corpus == c, model == m), corpus = c, tag = tag)
      result = model_cross_val_logistic(paste0("prop_subj", form), combined_df %>% filter(corpus == c, model == m), corpus = c, tag = tag)

      
      preds = data.frame(result[1]) %>%
        mutate(
          llh = - exp(pred) + y * pred - log(factorial(y)),
          tag = tag)
      
      pred_df = rbind(pred_df, preds %>% mutate(corpus = c, model = m))
      coeff_df = rbind(coeff_df, data.frame(result[2]) %>% mutate(corpus = c, model = m))

    }
  }
}

#write.csv(pred_df, "./fits/agg_poisson_preds.csv")
#write.csv(coeff_df, "./fits/agg_poisson_coeffs.csv")

write.csv(pred_df, "./fits/agg_logistic_preds.csv")
write.csv(coeff_df, "./fits/agg_logistic_coeffs.csv")


```


```{r}

#pred_df = read.csv("./fits/agg_poisson_preds.csv")
#coeff_df = read.csv("./fits/agg_poisson_coeffs.csv")

pred_df = read.csv("./fits/agg_logistic_preds.csv")
coeff_df = read.csv("./fits/agg_logistic_coeffs.csv")

tags = unique(pred_df$tag)
dll_df = data.frame()

for (c in corpora){
for (m in models){
  temp_df = pred_df %>% filter(corpus == c, model == m)
      
  for(tag1 in tags){
      
      if(tag1 != "Baseline"){
        
        dll1 = temp_df[temp_df$tag  == tag1,]$llh
        dll2 = temp_df[temp_df$tag  == "Baseline",]$llh
        dll_diff = dll1 - dll2
        dll_diff = dll_diff[!is.na(dll_diff)]
        ptest = perm.test(dll_diff, num.sim = 10)
        dll_df = rbind(dll_df, data.frame(dll_diff) %>% mutate(tag=tag1, corpus = c, model = m, pval = as.numeric(ptest$p.value)))
      }
  }
}
}

```



```{r}

plot_df = dll_df %>%
  drop_na() %>%
  mutate(theory = case_when(
    tag == "NPMI" | tag == "E[NPMI]" ~ "Reanalysis",
    tag == "PPMI" | tag == "E[PPMI]" ~ "Reactivation",
    is.na(tag) ~ "Ensemble"
  )) %>%
  mutate(tag = factor(tag, levels = c("PMI", "PPMI", "NPMI", "PPMI+NPMI",  "E[PMI]", "E[PPMI]", "E[NPMI]", "E[PPMI]+E[NPMI]", "All Predictors"))) %>%
  group_by(corpus, tag, theory, model) %>%
    summarise(m = mean(dll_diff),
              s = std.error(dll_diff),
              upper = m + s * 1.96,
              lower = m - s * 1.96,
              pval = unique(pval)) %>%
  ungroup()
  
plot_df %>%
  ggplot(aes(x = tag, y=m, color = theory)) +
    geom_hline(yintercept = 0, color = "#7cd82b", linetype="dashed") +
    geom_point(size = 2) +
    geom_errorbar(aes(ymax = upper, ymin = lower), width = 0.4) +
    facet_grid(corpus~model, scales = "free_y") +
    ylab("ΔLogLik") +
    labs(color="") +
    #scale_color_manual(values=c("#8277BB", "#BB7A74")) +
    #ggtitle("Regression Count Between Words") +
    theme(
      axis.text.x = element_text(angle = 45, hjust = 1, size = 9),
      axis.title.x = element_blank(),
      axis.text.y = element_text(angle = 90, hjust = 0.5),
      legend.position = "right"
    )

#ggsave("./images/agg_poisson.pdf", device="pdf", width = 8, height = 4)
ggsave("./images/agg_binom.pdf", device="pdf", width = 8, height = 4)

```
```{r}

# This block looks at the comparison of NPMI and E[NPMI] to see if the expectation is performing significantly better here

#pred_df = read.csv("./fits/agg_poisson_preds.csv")

pred_df = read.csv("./fits/agg_logistic_preds.csv")

dll_npmi_comp = data.frame()

for (c in corpora){
  for (m in models){
    temp_df = pred_df %>% filter(corpus == c, model == m)
    dll1 = temp_df[temp_df$tag  == "E[NPMI]",]$llh
    dll2 = temp_df[temp_df$tag  == "NPMI",]$llh
    dll_diff = dll1 - dll2
    dll_diff = dll_diff[!is.na(dll_diff)]
    ptest = perm.test(dll_diff, num.sim = 1000)
    dll_npmi_comp = rbind(dll_npmi_comp, data.frame(corpus = c, model = m, pval = as.numeric(ptest$p.value)))
  }
}

dll_npmi_comp 

```

## ============
## Coefficients 
## =============

```{r}
  
c_df = read.csv("./fits/agg_logistic_coeffs.csv")

coeff_agg_df = c_df %>%
  filter(term != "(Intercept)") %>%
  group_by(term, corpus, model) %>%
    summarise(
      m = mean(estimate), s = std.error(estimate),
      upper = m + 1.96 * s, lower = m - 1.96 * s
    ) %>%
  ungroup() %>%
  mutate(f1 = if_else(term %in% c("freq", "len", "surp"), 1, 0),
         f2 = if_else(tag == "Baseline", 1, 0),
         x = if_else(f1 == 1 & f2 == 0, 1, 0)) %>%
  filter(x != 1) %>%
  dplyr::select(-f1, -f2, -x)


coeff_agg_df %>%
  #mutate(ci = s * 1.96) %>%
  filter(term != "dist") %>%
  #mutate(term = factor(term, levels = c("freq", "len", "surp", "max_surp", "max_pmi", "max_topkj", "max_topkji", "max_kld"), labels = c("Frequency", "Length", "Surprisal", "Max Surprisal", "Max PMI", "Max Top-K↑", "Max Top-k↓", "Max KLD"))) %>%
  ggplot(aes(x = term, y = m, color = model, fill = model)) +
    geom_hline(yintercept = 0, color = "blue", alpha = 0.5, linetype = "dotted") +
    geom_bar(stat = "identity", alpha=0.5, position = position_dodge(width = 0.9)) +
    geom_errorbar(aes(ymin = lower, ymax = upper), width = 0, position = position_dodge(width = 0.9)) +
    ylab("Coefficient Estimate") +
    xlab("Coefficient Term") +
  #scale_color_brewer( palette = "Set3") +
  facet_grid(.~corpus, scales = "free_y") +
  theme(
    axis.text.x = element_text(angle = 45, hjust = 1),
    legend.position = "bottom"
  )

ggsave("./images/logistic_coeffs.pdf", device = "pdf", width = 8 , height = 3.5)


```

```{r}
coeff_agg_df %>%
  filter(term == "dist") %>%
  #mutate(term = factor(term, levels = c("freq", "len", "surp", "max_surp", "max_pmi", "max_topkj", "max_topkji", "max_kld"), labels = c("Frequency", "Length", "Surprisal", "Max Surprisal", "Max PMI", "Max Top-K↑", "Max Top-k↓", "Max KLD"))) %>%
  ggplot(aes(x = term, y = estimate, color = corpus, shape = model)) +
    geom_hline(yintercept = 0, color = "blue", alpha = 0.5, linetype = "dotted") +
    geom_jitter(size = 1, alpha = 0.2) +
    #geom_errorbar(aes(ymin = lower, ymax = upper)) +
    ylab("Coefficient Estimate") +
    xlab("Coefficient Term") +
  #facet_grid(.~model, scales = "free_y") +
  theme(
    axis.text.x = element_text(angle = 45, hjust = 1),
    legend.position = "none"
  )

```







